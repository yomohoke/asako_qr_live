<!DOCTYPE html>
<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script src="https://aframe.io/releases/1.5.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.5/dist/mindar-image-aframe.prod.js"></script>
    
    <script>
      // ▼ ここがTouchDesigner的な部分（カスタムシェーダー）
      AFRAME.registerComponent('audio-reactive-mesh', {
        init: function () {
          this.analyser = null;
          this.dataArray = null;
          
          // メッシュ（平面）を作成
          const geometry = new THREE.PlaneGeometry(1, 1, 32, 32); // 32x32分割のメッシュ
          
          // シェーダーマテリアル（ここがビジュアルの肝）
          const material = new THREE.ShaderMaterial({
            wireframe: true, // ワイヤーフレーム表示（カッコよく見せるため）
            transparent: true,
            uniforms: {
              uTime: { value: 0 },
              uAudio: { value: 0.0 } // 音の大きさを渡す変数
            },
            // 頂点シェーダー（形を変える）
            vertexShader: `
              varying vec2 vUv;
              uniform float uTime;
              uniform float uAudio;
              
              void main() {
                vUv = uv;
                vec3 pos = position;
                
                // 【演出】中心からの距離を計算
                float d = distance(uv, vec2(0.5));
                
                // 【演出】音に合わせて波打たせる (TouchDesignerのNoise CHOP的な処理)
                float wave = sin(pos.x * 10.0 + uTime * 5.0) * cos(pos.y * 10.0 + uTime * 5.0);
                
                // z軸（高さ）を変化させる
                pos.z += wave * uAudio * 0.5 * (1.0 - d); 
                
                gl_Position = projectionMatrix * modelViewMatrix * vec4(pos, 1.0);
              }
            `,
            // フラグメントシェーダー（色を決める）
            fragmentShader: `
              varying vec2 vUv;
              uniform float uAudio;
              
              void main() {
                // 音が大きいほど赤く、普段は黒く
                vec3 color = mix(vec3(0.0, 0.0, 0.0), vec3(1.0, 0.0, 0.2), uAudio * 2.0);
                gl_FragColor = vec4(color, 0.8);
              }
            `
          });
          
          this.mesh = new THREE.Mesh(geometry, material);
          this.el.setObject3D('mesh', this.mesh);
          
          // 音声解析の準備（ユーザーアクション後に開始）
          document.body.addEventListener('click', this.setupAudio.bind(this), { once: true });
        },
        
        setupAudio: function () {
          const audioEl = document.querySelector('#bgm');
          if(!audioEl) return;

          // AudioContextの作成
          const context = new (window.AudioContext || window.webkitAudioContext)();
          const src = context.createMediaElementSource(audioEl);
          const analyser = context.createAnalyser();
          
          src.connect(analyser);
          analyser.connect(context.destination);
          
          analyser.fftSize = 256;
          this.analyser = analyser;
          this.dataArray = new Uint8Array(analyser.frequencyBinCount);
          
          audioEl.play();
        },
        
        tick: function (time, timeDelta) {
          if (!this.mesh) return;
          
          // 時間をシェーダーに渡す
          this.mesh.material.uniforms.uTime.value = time / 1000;
          
          if (this.analyser) {
            // 音声データを取得
            this.analyser.getByteFrequencyData(this.dataArray);
            
            // 低音域（Bass）の平均レベルを取得
            let sum = 0;
            for(let i = 0; i < 10; i++) { // 低い周波数帯だけ見る
                sum += this.dataArray[i];
            }
            let avg = sum / 10 / 255; // 0.0 〜 1.0 に正規化
            
            // シェーダーに渡す（スムージングして滑らかに）
            this.mesh.material.uniforms.uAudio.value += (avg - this.mesh.material.uniforms.uAudio.value) * 0.1;
          }
        }
      });

      // ▼ 機材が「にゅっ」と生えてくるアニメーション
      AFRAME.registerComponent('grow-on-start', {
        init: function () {
          this.el.setAttribute('scale', '0 0 0'); // 最初は極小
          document.body.addEventListener('click', () => {
             // 簡易的なアニメーション (本来はGSAP推奨だが今回はベタ書き)
             let s = 0;
             const grow = setInterval(() => {
                 s += 0.05;
                 this.el.setAttribute('scale', `${s} ${s} ${s}`);
                 if (s >= 0.5) clearInterval(grow);
             }, 50);
          }, { once: true });
        }
      });
    </script>
  </head>
  <body>
    <div style="position: absolute; bottom: 20px; width: 100%; text-align: center; z-index: 1000; color: white;">
        TAP SCREEN TO START LIVE
    </div>

    <a-scene mindar-image="imageTargetSrc: ./targets.mind;" color-space="sRGB" renderer="colorManagement: true, physicallyCorrectLights" vr-mode-ui="enabled: false" device-orientation-permission-ui="enabled: false">
      
      <a-assets>
        <a-asset-item id="avatarModel" src="./model.gltf"></a-asset-item>
        <audio id="bgm" src="./music.m4a" preload="auto" crossorigin="anonymous"></audio>
      </a-assets>

      <a-camera position="0 0 0" look-controls="enabled: false"></a-camera>

      <a-entity mindar-image-target="targetIndex: 0">
        
        <a-entity audio-reactive-mesh position="0 0 0.05"></a-entity>
        
        <a-gltf-model src="#avatarModel" rotation="0 0 0" position="0 0 0" grow-on-start></a-gltf-model>
        
      </a-entity>
    </a-scene>
  </body>
</html>